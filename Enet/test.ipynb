{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import networkx as nx\n",
    "from util_functions import sample_train_val_test\n",
    "import _pickle as cPickle\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 2708)\n"
     ]
    }
   ],
   "source": [
    "data = loadmat(\"./data/cora.mat\")\n",
    "label = data['label'] #获取label\n",
    "net_c = data['net']   # input: clean network (not consider missing links) 无噪声边\n",
    "print(net_c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 2708)\n"
     ]
    }
   ],
   "source": [
    "data = loadmat(\"./data/cora_n0.1.mat\")\n",
    "net = data['net']   # input: flawed network 缺陷网络\n",
    "node_num = net.shape[0] #获取节点数量\n",
    "print(net.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of nodes: 2708\n",
      "# of clean/all edges: 5278/5805\n"
     ]
    }
   ],
   "source": [
    "edges = nx.from_scipy_sparse_array(net).edges() #带噪声的边\n",
    "edges_clean = nx.from_scipy_sparse_array(net_c).edges() #无噪声的边\n",
    "\n",
    "print(f'# of nodes: {node_num}')\n",
    "print(f'# of clean/all edges: {len(edges_clean)}/{len(edges)}')\n",
    "num_noisy_edge = len(edges) - len(edges_clean) #获取噪声边的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attribute dimension: (2708, 1433)\n"
     ]
    }
   ],
   "source": [
    "#节点属性\n",
    "if  'group' in data:\n",
    "    # load node attributes (here a.k.a. node classes)\n",
    "    try:\n",
    "        attributes = data['group'].toarray().astype('float32')\n",
    "    except AttributeError:\n",
    "        attributes = data['group'].astype('float32')\n",
    "else:\n",
    "    attributes = None\n",
    "print('attribute dimension: {}'.format(attributes.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING LINK PREDICTION-- # train_pos: 428, # train_neg: 428, # val_pos: 53, # val_neg: 265, # test_pos: 53, # test_neg: 265\n"
     ]
    }
   ],
   "source": [
    "#Sample train and test links\n",
    "split_ratio=[8,1,1]#80%训练,10%验证,10%测试\n",
    "missing_ratio=0.1\n",
    "neg_pos_ratio=5\n",
    "train_val_test, missing_links = sample_train_val_test(edges, edges_clean, net,split_ratio,missing_ratio)\n",
    "#pos:真正的缺失链路\n",
    "#neg: 假的缺失链路，包括两种情况: 1.噪声链路 2.链路本身不存在\n",
    "print('MISSING LINK PREDICTION-- # train_pos: %d, # train_neg: %d, # val_pos: %d, # val_neg: %d, # test_pos: %d, # test_neg: %d' % (\n",
    "    len(train_val_test['train'][0][0]), len(train_val_test['train'][1][0]), len(train_val_test['val'][0][0]),\n",
    "    len(train_val_test['val'][1][0]), len(train_val_test['test'][0][0]), len(train_val_test['test'][1][0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = net.copy()  # the observed network\n",
    "# mask missing links\n",
    "for key, value in train_val_test.items():#在A的测试集上测试\n",
    "    A[value[0][0], value[0][1]] = 0\n",
    "    A[value[0][1], value[0][0]] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos_ratio=5\n",
    "pos_noisy_links = [e for e in edges if e not in edges_clean and e[::-1] not in edges_clean]\n",
    "remain_clean_links = [e for e in edges_clean if e not in missing_links and e[::-1] not in missing_links]#既不是缺失边也不是噪声边\n",
    "perm = random.sample(range(len(remain_clean_links)), len(pos_noisy_links) * neg_pos_ratio)\n",
    "neg_noisy_links = [remain_clean_links[i] for i in perm]\n",
    "noisy_candidate = pos_noisy_links + neg_noisy_links\n",
    "row = np.array(noisy_candidate)[:,0]; col = np.array(noisy_candidate)[:,1]\n",
    "data = [1 for i in range(len(row))]\n",
    "Identity = csc_matrix((data, (row,col)), shape=A.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
